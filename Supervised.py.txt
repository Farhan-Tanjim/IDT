import os
from glob import glob
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import re
import nltk
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
import tensorflow as tf
from tensorflow import keras

# Keras Functional API

import tensorflow as tf
from tensorflow import keras
from keras.layers import Input, Dense, Activation, Dropout,Flatten,Embedding
from keras.layers import Conv1D,MaxPooling1D,GlobalAveragePooling1D
from keras.models import Model
from tensorflow.keras.optimizers import Adam,SGD,Nadam,RMSprop
from tensorflow.keras.models import load_model
from keras.layers import Embedding, SpatialDropout1D, LSTM, GlobalMaxPooling1D, Dense

n_most_common_words = 17030
max_len = 200
embedding_dim=200
tokenizer = Tokenizer(num_words=n_most_common_words, filters='!"#$%&()*+,-./:;<=>?@[\]^_`{|}~', lower=True)
tokenizer.fit_on_texts(data['Text'].values)
sequences = tokenizer.texts_to_sequences(data['Text'].values)
word_index = tokenizer.word_index
print('Found %s unique tokens.' % len(word_index))
X = pad_sequences(sequences, maxlen=max_len)
y = data['Sub-task A']
from sklearn.model_selection import train_test_split

# Set the random seed value
random_seed = 42

# Split the dataset into train and test sets
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed, stratify=y)


import tensorflow as tf
tf.keras.backend.clear_session()

def CNN():
    model = tf.keras.Sequential()
    # model.add(tf.keras.layers.Input(shape=(max_length,)))
    model.add(tf.keras.layers.Embedding(n_most_common_words, embedding_dim, input_length=X.shape[1]))
    model.add(tf.keras.layers.Conv1D(128, 3, activation='relu'))
    model.add(tf.keras.layers.MaxPooling1D(2))

    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)))  # Add Bidirectional LSTM layer
    model.add(tf.keras.layers.Activation('tanh'))  # Add Tanh activation layer
    model.add(tf.keras.layers.Dropout(0.3))  # Add Dropout layer
    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))
    #model.add(tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(10, activation='softmax')))

    return model

# Call the model
cnnbilstm_model = CNN()

# Print the model summary
cnnbilstm_model.summary()

 cnnbilstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])
 history = cnnbilstm_model.fit(X_train, Y_train, epochs=5, batch_size=64,validation_split=0.1)

import numpy as np
from sklearn.metrics import confusion_matrix, classification_report

# Evaluate the model on the test set
accr = cnnbilstm_model.evaluate(X_test, Y_test)

# Get the predicted probabilities for each class
y_pred_probs = cnnbilstm_model.predict(X_test)

# Convert the predicted probabilities to binary predictions
y_pred_binary = np.array([1 if prob >= 0.5 else 0 for prob in y_pred_probs])

# Get the true labels from Y_test
y_true = np.array(Y_test)

# Calculate the confusion matrix
cm = confusion_matrix(y_true, y_pred_binary)

# Print the confusion matrix
print("Confusion Matrix:")

# Print the classification report
print("\nClassification Report:")
print(classification_report(y_true, y_pred_binary))

# Print the test set loss and accuracy
print('\nTest set\n  Loss: {:0.3f}\n  Accuracy: {:0.3f}'.format(accr[0], accr[1]))

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix


# Compute the confusion matrix
cm = confusion_matrix(y_true, y_pred_binary)
# Plot the confusion matrix as a heatmap
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')

# Add axis labels and title
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

